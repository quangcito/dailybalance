import OpenAI from 'openai';
import { getConversationHistory, saveInteractionLogEmbedding } from '../vector-db/pinecone.ts';
import { ReasoningOutput } from './reasoning-layer.js';
import { StructuredAnswer } from '@/types/conversation';
import { InteractionLog } from '@/types/user'; // Import InteractionLog type

// Ensure environment variables are set
const openaiApiKey = process.env.OPENAI_API_KEY;

if (!openaiApiKey) {
  throw new Error('Missing OpenAI API Key (OPENAI_API_KEY) in environment variables.');
}

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: openaiApiKey,
});

const CONVERSATION_LAYER_SYSTEM_PROMPT = `You are the Conversation Layer of the DailyBalance Answer Engine. Your goal is to refine the preliminary insights and suggestions from the Reasoning Layer into a final, natural, and helpful response for the user, incorporating relevant conversation history and the updated daily calorie balance.

Inputs Provided:
1.  User Query: The most recent question from the user.
2.  Reasoning Output: A JSON object containing { insights: string, suggestions?: string[], warnings?: string[], derivedData?: Record<string, any>, agenticLogIntents?: any[] } from the previous layer. Note: agenticLogIntents have already been processed; focus on the other fields. The 'derivedData' field should contain 'dailyCaloriesConsumed', 'dailyCaloriesBurned', and 'netCalories'.
3.  Conversation History: Recent turns from the current session (user queries and assistant responses).
4.  Calorie Summary:
    *   dailyCaloriesConsumed (number): Total calories consumed today.
    *   dailyCaloriesBurned (number): Total calories burned from exercise today.
    *   netCalories (number | undefined): Calculated net balance (TDEE - consumed + burned). May be undefined if TDEE is missing.
    *   userTDEE (number | undefined): User's estimated TDEE (target calories).

Your Task:
- Review the Reasoning Output (insights, suggestions, warnings, derivedData), Conversation History, and the provided Calorie Summary.
- Synthesize these inputs into a coherent, user-friendly, and contextually relevant response.
- Address the user's query directly, using the insights provided. **IMPORTANT: Check the 'insights' field for any notes about existing logs (e.g., "(Note: Oatmeal already logged for today)"). If such a note exists, YOU MUST explicitly mention this fact in your response text (e.g., "I see you already logged oatmeal today...").**
- **If the Calorie Summary values (consumed, burned, net, TDEE) are available and relevant to the query, incorporate a brief summary of the user's net calorie balance (e.g., "Your net balance for today is currently X calories [Consumed: Y, Burned: Z, Target: TDEE]."). Adjust wording if TDEE or netCalories are undefined.**
- Naturally weave in suggestions and warnings from the Reasoning Output where appropriate.
- Maintain a helpful and encouraging tone suitable for a health and wellness assistant.
- Output ONLY a JSON object matching the StructuredAnswer interface: { text: string, suggestions?: string[], dataSummary?: Record<string, any> }. Do not include any other text or explanations outside the JSON structure.
    - Ensure the 'text' field contains the main conversational response, including the net calorie balance summary if applicable.
    - Populate 'suggestions' if relevant suggestions were generated by the reasoning layer.
    - **Crucially, populate the 'dataSummary' field using the information provided in the 'derivedData' field from the Reasoning Output. Ensure this includes 'dailyCaloriesConsumed', 'dailyCaloriesBurned', and 'netCalories' from the input Calorie Summary.**

Example:
- Reasoning Output: { "insights": "An apple fits your calorie goals.", "suggestions": ["Pair with protein."], "derivedData": { "dailyCaloriesConsumed": 595, "dailyCaloriesBurned": 0, "netCalories": 1605, "userTDEE": 2200, "itemCalories": 95 } }
- History: [...]
- Calorie Summary: { dailyCaloriesConsumed: 595, dailyCaloriesBurned: 0, netCalories: 1605, userTDEE: 2200 }
- Output: { "text": "An apple is a great low-calorie choice (around 95 kcal) that fits well with your goals! Your net balance for today is currently 1605 calories (Consumed: 595, Burned: 0, Target: 2200). To make it more satisfying, consider pairing it with a protein source like a handful of nuts or some yogurt.", "suggestions": ["Pair apple with protein (nuts, yogurt)"], "dataSummary": { "dailyCaloriesConsumed": 595, "dailyCaloriesBurned": 0, "netCalories": 1605, "userTDEE": 2200, "itemCalories": 95 } }

Focus on clarity, helpfulness, and maintaining conversational flow. Ensure the output JSON strictly adheres to the StructuredAnswer format, especially including the updated calorie data in dataSummary.`;

/**
 * Generates the final structured answer by refining reasoning output
 * and incorporating conversation history.
 *
 * @param userId - The ID of the user.
 * @param sessionId - The ID of the current conversation session.
 * @param query - The user's current query.
 * @param reasoningOutput - The output from the Reasoning Layer.
 * @returns A StructuredAnswer object or a default error object.
 */
export async function generateFinalResponse(
  userId: string,
  sessionId: string,
  query: string,
  reasoningOutput: ReasoningOutput | null,
  // UPDATED: Use specific calorie parameters
  dailyCaloriesConsumed?: number,
  dailyCaloriesBurned?: number,
  netCalories?: number,
  tdee?: number // Keep TDEE for context
): Promise<StructuredAnswer> {
  console.log(`Conversation Layer: Generating final response for query: "${query}"`);

  if (!reasoningOutput || reasoningOutput.error) {
    console.error('Conversation Layer: Received error or null output from Reasoning Layer.');
    return {
      text: "I encountered an issue while processing your request. Please try again.",
      error: reasoningOutput?.error || "Reasoning layer failed.",
    };
  }

  // 1. Fetch conversation history (non-blocking for the main response generation)
  let history: any[] = [];
  try {
    // Limit history length to avoid excessive token usage
    history = await getConversationHistory(sessionId, 5); // Get last 5 turns
    console.log(`Conversation Layer: Fetched ${history.length} turns from history.`);
  } catch (histError) {
    console.error('Conversation Layer: Failed to fetch conversation history:', histError);
    // Proceed without history, but log the error
  }

  // 2. Construct the prompt for the final LLM call
  const userMessageContent = `
User Query: ${query}
Reasoning Output: ${JSON.stringify(reasoningOutput)}
Conversation History: ${JSON.stringify(history)}
Calorie Summary:
  - Daily Calories Consumed: ${dailyCaloriesConsumed ?? 'Not available'}
  - Daily Calories Burned: ${dailyCaloriesBurned ?? 'Not available'}
  - Net Calories: ${netCalories ?? 'Not available (Missing TDEE?)'}
  - User TDEE: ${tdee ?? 'Not available'}

Generate the final JSON output (StructuredAnswer) based on these inputs, incorporating the net calorie balance info into the text and dataSummary where appropriate.
`;

  try {
    // 3. Call OpenAI API (GPT-4o-mini)
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini', // As specified in product context
      messages: [
        { role: 'system', content: CONVERSATION_LAYER_SYSTEM_PROMPT },
        { role: 'user', content: userMessageContent },
      ],
      response_format: { type: 'json_object' },
      temperature: 0.7, // Slightly higher temp for more natural language
    });

    const responseContent = completion.choices[0]?.message?.content;

    if (!responseContent) {
      console.error('Conversation Layer: No content received from OpenAI.');
      return { text: "Sorry, I couldn't generate a response.", error: 'No content from LLM.' };
    }

    // 4. Parse the response
    let finalAnswer: StructuredAnswer;
    try {
      finalAnswer = JSON.parse(responseContent);
      console.log('Conversation Layer: Successfully generated final response.');
    } catch (parseError) {
      console.error('Conversation Layer: Failed to parse JSON response from OpenAI:', parseError);
      console.error('Raw response content:', responseContent);
      return { text: "Sorry, I had trouble formatting the response.", error: 'Failed to parse LLM response.' };
    }

    // 5. Save interaction log with embedding to Pinecone (async, non-blocking)
    const interactionLogEntry: InteractionLog = {
        userId: userId,
        sessionId: sessionId,
        timestamp: new Date().toISOString(),
        query: query,
        llmResponse: finalAnswer // finalAnswer is the StructuredAnswer
        // userFeedback and metadata are optional
    };

    saveInteractionLogEmbedding(interactionLogEntry).catch(saveError => {
        console.error('Conversation Layer: Failed to save interaction log embedding:', saveError);
        // Don't fail the response to the user if saving fails
    });


    return finalAnswer;

  } catch (error) {
    console.error('Conversation Layer: Error calling OpenAI API:', error);
    const errorMessage = error instanceof Error ? error.message : 'Unknown OpenAI API error';
    return { text: "Sorry, an error occurred while contacting the AI service.", error: `OpenAI API Error: ${errorMessage}` };
  }
}
