import OpenAI from 'openai';
import { getConversationHistory, saveInteractionLogEmbedding } from '../vector-db/pinecone.ts';
import { ReasoningOutput } from './reasoning-layer.js';
import { StructuredAnswer } from '@/types/conversation';
import { InteractionLog } from '@/types/user'; // Import InteractionLog type

// Ensure environment variables are set
const openaiApiKey = process.env.OPENAI_API_KEY;

if (!openaiApiKey) {
  throw new Error('Missing OpenAI API Key (OPENAI_API_KEY) in environment variables.');
}

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: openaiApiKey,
});

const CONVERSATION_LAYER_SYSTEM_PROMPT = `You are the Conversation Layer of the DailyBalance Answer Engine. Your goal is to refine the preliminary insights and suggestions from the Reasoning Layer into a final, natural, and helpful response for the user, incorporating relevant conversation history and daily calorie tracking.

Inputs Provided:
1.  User Query: The most recent question from the user.
2.  Reasoning Output: A JSON object containing { insights: string, suggestions?: string[], warnings?: string[], derivedData?: Record<string, any>, agenticLogsToCreate?: any[] } from the previous layer. Note: agenticLogsToCreate has already been processed; focus on the other fields.
3.  Conversation History: Recent turns from the current session (user queries and assistant responses).
4.  Daily Calories Consumed: The total calories consumed by the user today based on logs (may be 0).
5.  User TDEE: The user's estimated Total Daily Energy Expenditure (target calories).

Your Task:
- Review the Reasoning Output (insights, suggestions, warnings, derivedData), Conversation History, Daily Calories Consumed, and User TDEE.
- Synthesize these inputs into a coherent, user-friendly, and contextually relevant response.
- Address the user's query directly, using the insights provided. **IMPORTANT: Check the 'insights' field for any notes about existing logs (e.g., "(Note: Oatmeal already logged for today)"). If such a note exists, YOU MUST explicitly mention this fact in your response text (e.g., "I see you already logged oatmeal today...").**
- **If Daily Calories Consumed and User TDEE are available and relevant to the query, incorporate a brief summary of the user's progress (e.g., "You've had X out of your target Y calories today.").**
- Naturally weave in suggestions and warnings from the Reasoning Output where appropriate.
- Maintain a helpful and encouraging tone suitable for a health and wellness assistant.
- Output ONLY a JSON object matching the StructuredAnswer interface: { text: string, suggestions?: string[], dataSummary?: Record<string, any> }. Do not include any other text or explanations outside the JSON structure.
    - Ensure the 'text' field contains the main conversational response, including any calorie tracking info if applicable.
    - Populate 'suggestions' if relevant suggestions were generated by the reasoning layer.
    - **Crucially, populate the 'dataSummary' field using the information provided in the 'derivedData' field from the Reasoning Output. You can also add 'dailyCaloriesConsumed' and 'userTDEE' to this summary if they were provided.**

Example:
- Reasoning Output: { "insights": "An apple fits your calorie goals.", "suggestions": ["Pair with protein."], "derivedData": { "itemCalories": 95, "remainingCalories": 705 } }
- History: [...]
- Output: { "text": "An apple is a great low-calorie choice (around 95 kcal) that fits well with your goals! Based on your logs, you have about 705 kcal remaining today. To make it more satisfying, consider pairing it with a protein source like a handful of nuts or some yogurt.", "suggestions": ["Pair apple with protein (nuts, yogurt)"], "dataSummary": { "itemCalories": 95, "remainingCalories": 705 } }

Focus on clarity, helpfulness, and maintaining conversational flow. Ensure the output JSON strictly adheres to the StructuredAnswer format, especially including the dataSummary based on derivedData.`;

/**
 * Generates the final structured answer by refining reasoning output
 * and incorporating conversation history.
 *
 * @param userId - The ID of the user.
 * @param sessionId - The ID of the current conversation session.
 * @param query - The user's current query.
 * @param reasoningOutput - The output from the Reasoning Layer.
 * @returns A StructuredAnswer object or a default error object.
 */
export async function generateFinalResponse(
  userId: string,
  sessionId: string,
  query: string,
  reasoningOutput: ReasoningOutput | null,
  // NEW: Add calorie tracking parameters
  dailyCalories?: number,
  tdee?: number
): Promise<StructuredAnswer> {
  console.log(`Conversation Layer: Generating final response for query: "${query}"`);

  if (!reasoningOutput || reasoningOutput.error) {
    console.error('Conversation Layer: Received error or null output from Reasoning Layer.');
    return {
      text: "I encountered an issue while processing your request. Please try again.",
      error: reasoningOutput?.error || "Reasoning layer failed.",
    };
  }

  // 1. Fetch conversation history (non-blocking for the main response generation)
  let history: any[] = [];
  try {
    // Limit history length to avoid excessive token usage
    history = await getConversationHistory(sessionId, 5); // Get last 5 turns
    console.log(`Conversation Layer: Fetched ${history.length} turns from history.`);
  } catch (histError) {
    console.error('Conversation Layer: Failed to fetch conversation history:', histError);
    // Proceed without history, but log the error
  }

  // 2. Construct the prompt for the final LLM call
  const userMessageContent = `
User Query: ${query}
Reasoning Output: ${JSON.stringify(reasoningOutput)}
Conversation History: ${JSON.stringify(history)}
Daily Calories Consumed: ${dailyCalories ?? 'Not available'}
User TDEE: ${tdee ?? 'Not available'}

Generate the final JSON output (StructuredAnswer) based on these inputs, incorporating the calorie tracking info into the text and dataSummary where appropriate.
`;

  try {
    // 3. Call OpenAI API (GPT-4o-mini)
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini', // As specified in product context
      messages: [
        { role: 'system', content: CONVERSATION_LAYER_SYSTEM_PROMPT },
        { role: 'user', content: userMessageContent },
      ],
      response_format: { type: 'json_object' },
      temperature: 0.7, // Slightly higher temp for more natural language
    });

    const responseContent = completion.choices[0]?.message?.content;

    if (!responseContent) {
      console.error('Conversation Layer: No content received from OpenAI.');
      return { text: "Sorry, I couldn't generate a response.", error: 'No content from LLM.' };
    }

    // 4. Parse the response
    let finalAnswer: StructuredAnswer;
    try {
      finalAnswer = JSON.parse(responseContent);
      console.log('Conversation Layer: Successfully generated final response.');
    } catch (parseError) {
      console.error('Conversation Layer: Failed to parse JSON response from OpenAI:', parseError);
      console.error('Raw response content:', responseContent);
      return { text: "Sorry, I had trouble formatting the response.", error: 'Failed to parse LLM response.' };
    }

    // 5. Save interaction log with embedding to Pinecone (async, non-blocking)
    const interactionLogEntry: InteractionLog = {
        userId: userId,
        sessionId: sessionId,
        timestamp: new Date().toISOString(),
        query: query,
        llmResponse: finalAnswer // finalAnswer is the StructuredAnswer
        // userFeedback and metadata are optional
    };

    saveInteractionLogEmbedding(interactionLogEntry).catch(saveError => {
        console.error('Conversation Layer: Failed to save interaction log embedding:', saveError);
        // Don't fail the response to the user if saving fails
    });


    return finalAnswer;

  } catch (error) {
    console.error('Conversation Layer: Error calling OpenAI API:', error);
    const errorMessage = error instanceof Error ? error.message : 'Unknown OpenAI API error';
    return { text: "Sorry, an error occurred while contacting the AI service.", error: `OpenAI API Error: ${errorMessage}` };
  }
}
